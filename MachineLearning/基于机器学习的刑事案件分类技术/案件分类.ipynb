{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于机器学习的刑事案件分类技术",
   "id": "e2fdf388e9ffb69b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 文本预处理。\n",
    "\n",
    "从语料库读取信息并进行文本清洗以及去停用词。\n",
    "\n",
    "使用jieba以及nltk"
   ],
   "id": "c28f26915d2ad16c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:19:08.981381Z",
     "start_time": "2024-05-30T07:19:06.081066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#准备工作\n",
    "import os\n",
    "import win32com.client\n",
    "import pandas as pd"
   ],
   "id": "9c8d397523520cd0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 转换格式\n",
    "\n",
    "doc读取太慢，转为txt"
   ],
   "id": "cc7915bf47b53fdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:19:30.624755Z",
     "start_time": "2024-05-30T07:19:08.981381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from win32com import client as wc\n",
    "from docx import Document\n",
    "\n",
    "def doc_to_docx(doc_file_path, docx_file_path):\n",
    "    \"\"\"\n",
    "    使用 Word 应用程序将 .doc 文件转换为 .docx 文件\n",
    "    :param doc_file_path: 输入的 .doc 文件路径\n",
    "    :param docx_file_path: 输出的 .docx 文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        word = wc.Dispatch('Word.Application')\n",
    "        doc = word.Documents.Open(doc_file_path)\n",
    "        doc.SaveAs(docx_file_path, 12)  # 12 表示将 .doc 转为 .docx\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "        print(f\"Successfully converted {doc_file_path} to {docx_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting file {doc_file_path}: {str(e)}\")\n",
    "\n",
    "def docx_to_txt(docx_file_path, txt_file_path):\n",
    "    \"\"\"\n",
    "    使用 python-docx 将 .docx 文件转换为 .txt 文件\n",
    "    :param docx_file_path: 输入的 .docx 文件路径\n",
    "    :param txt_file_path: 输出的 .txt 文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 打开 .docx 文件\n",
    "        doc = Document(docx_file_path)\n",
    "        \n",
    "        # 创建新的 .txt 文件\n",
    "        with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "            # 将 .docx 中的内容写入 .txt 文件\n",
    "            for para in doc.paragraphs:\n",
    "                txt_file.write(para.text)\n",
    "                txt_file.write('\\n')  # 添加换行符\n",
    "        \n",
    "        print(f\"Successfully converted {docx_file_path} to {txt_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting file {docx_file_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "def read_txt_file(txt_file_path):\n",
    "    \"\"\"\n",
    "    读取 TXT 文件的内容。\n",
    "    :param txt_file_path: 输入的 TXT 文件路径\n",
    "    :return: 文件内容\n",
    "    \"\"\"\n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_doc_files(doc_folder_path, txt_folder_path):\n",
    "    \"\"\"\n",
    "    将文件夹中的所有 .doc 文件转换为 .txt 文件并读取其内容。\n",
    "    :param doc_folder_path: 包含 .doc 文件的文件夹路径\n",
    "    :param txt_folder_path: 用于保存 .txt 文件的文件夹路径\n",
    "    :return: 包含所有文档内容的列表\n",
    "    \"\"\"\n",
    "    if not os.path.exists(txt_folder_path):\n",
    "        os.makedirs(txt_folder_path)\n",
    "    \n",
    "    all_texts = []\n",
    "    \n",
    "    for filename in os.listdir(doc_folder_path):\n",
    "        if filename.endswith('.doc'):\n",
    "            doc_file_path = os.path.join(doc_folder_path, filename)\n",
    "            docx_file_path = os.path.join(doc_folder_path, filename.replace('.doc', '.docx'))\n",
    "            txt_file_path = os.path.join(txt_folder_path, filename.replace('.doc', '.txt'))\n",
    "            try:\n",
    "                doc_to_docx(doc_file_path, docx_file_path)\n",
    "                docx_to_txt(docx_file_path, txt_file_path)\n",
    "                text = read_txt_file(txt_file_path)\n",
    "                all_texts.append(text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return all_texts\n",
    "\n",
    "\n",
    "# 示例调用\n",
    "doc_folder_path = 'D:/基于机器学习的刑事案件分类技术/test'\n",
    "txt_folder_path = 'D:/基于机器学习的刑事案件分类技术/txt'\n",
    "all_texts = process_doc_files(doc_folder_path, txt_folder_path)"
   ],
   "id": "e6f5549e3a91338a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted D:/基于机器学习的刑事案件分类技术/test\\（2011）兴刑初字第176号谢利杰非法出售珍贵、濒危野生动....doc to D:/基于机器学习的刑事案件分类技术/test\\（2011）兴刑初字第176号谢利杰非法出售珍贵、濒危野生动....docx\n",
      "Successfully converted D:/基于机器学习的刑事案件分类技术/test\\（2011）兴刑初字第176号谢利杰非法出售珍贵、濒危野生动....docx to D:/基于机器学习的刑事案件分类技术/txt\\（2011）兴刑初字第176号谢利杰非法出售珍贵、濒危野生动....txt\n",
      "Successfully converted D:/基于机器学习的刑事案件分类技术/test\\（2012）北刑一初字第31号刑事判决书.doc to D:/基于机器学习的刑事案件分类技术/test\\（2012）北刑一初字第31号刑事判决书.docx\n",
      "Successfully converted D:/基于机器学习的刑事案件分类技术/test\\（2012）北刑一初字第31号刑事判决书.docx to D:/基于机器学习的刑事案件分类技术/txt\\（2012）北刑一初字第31号刑事判决书.txt\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 读取txt和doc文件",
   "id": "3845d7eeaad41c31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:19:30.648326Z",
     "start_time": "2024-05-30T07:19:30.628231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def load_files(directory):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            documents.append(load_txt_file(file_path))\n",
    "    return documents"
   ],
   "id": "fb43d32e4d96f319",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 清洗文本（使用正则表达式去除重复部分）",
   "id": "dd8c4c0086d4f418"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:35:41.798242Z",
     "start_time": "2024-05-30T07:35:41.766553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# 正则表达式函数\n",
    "def remove_header_footer(text):\n",
    "    # 移除标题和页眉页脚等无关信息，可以根据具体情况定制正则表达式\n",
    "    # 移除包含\"人民法院\"的子字符串\n",
    "    text = re.sub(r'\\b[\\u4e00-\\u9fa5]+人民法院\\b', '', text)\n",
    "    # 移除\"刑 事 判 决 书\"\n",
    "    text = re.sub(r'刑\\s*事\\s*判\\s*决\\s*书', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_case_number_and_date(text):\n",
    "    # 移除案号和日期等信息\n",
    "    text = re.sub(r'（\\d+）[\\u4e00-\\u9fa5]{2,4}字第\\d+号', '', text)\n",
    "    text = re.sub(r'\\d{4}年[\\u4e00-\\u9fa5]{2,4}月[\\u4e00-\\u9fa5]{2,4}日', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_prosecution_office(text):\n",
    "    # 移除公诉机关信息\n",
    "    return re.sub(r'公诉机关[\\u4e00-\\u9fa5]+。', '', text)\n",
    "\n",
    "def remove_judges_and_clerks(text):\n",
    "    # 移除审判员和书记员信息\n",
    "    text = re.sub(r'审判员[\\u4e00-\\u9fa5\\s]+', '', text)\n",
    "    return re.sub(r'书记员[\\u4e00-\\u9fa5\\s]+', '', text)\n",
    "\n",
    "def extract_labels(text):\n",
    "    \"\"\"\n",
    "    从文本中提取罪名\n",
    "    :param text: 输入文本\n",
    "    :return: 罪名\n",
    "    \"\"\"\n",
    "    # 正则表达式提取罪名\n",
    "    # 定义匹配罪名的正则表达式\n",
    "    crime_pattern = r'犯([\\u4e00-\\u9fa5]+罪)'\n",
    "    \n",
    "    # 使用正则表达式找到所有匹配项\n",
    "    crime_matches = re.findall(crime_pattern, text)\n",
    "    \n",
    "    # 去除重复项并返回列表\n",
    "    return list(set(crime_matches))\n",
    "\n",
    "def remove_other_irrelevant_info(text):\n",
    "# 移除包含\"公安局\"的子字符串\n",
    "    text = re.sub(r'\\b[\\u4e00-\\u9fa5]+公安局\\b', '', text)\n",
    "    # 移除包含\"看守所\"的子字符串\n",
    "    text = re.sub(r'\\b[\\u4e00-\\u9fa5]+看守所\\b', '', text)\n",
    "    return text\n",
    "\n",
    "# 清洗函数\n",
    "def clean_judgment_text(text):\n",
    "    text = remove_header_footer(text)\n",
    "    text = remove_case_number_and_date(text)\n",
    "    text = remove_prosecution_office(text)\n",
    "    text = remove_judges_and_clerks(text)\n",
    "    label = extract_labels(text)\n",
    "    text = remove_other_irrelevant_info(text)\n",
    "    return text, label\n"
   ],
   "id": "522add497b95a43b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 读取停用词表。",
   "id": "60542edfdfd515e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:19:30.694986Z",
     "start_time": "2024-05-30T07:19:30.683371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载中文停用词表\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        stop_words = set([line.strip() for line in file.readlines()])\n",
    "    return stop_words"
   ],
   "id": "c4d1d0fd56d2ed13",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 处理文本\n",
    "\n",
    "由于实在是太多，采用了多线程进行处理"
   ],
   "id": "619b4b459c5e900d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:35:47.670607Z",
     "start_time": "2024-05-30T07:35:47.642299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "def segment_and_filter(text, stopwords, allowed_pos):\n",
    "    \n",
    "    words_pos = pseg.cut(text)  # 分词并标注词性\n",
    "    # 过滤停用词和不需要的词性\n",
    "    filtered_words_pos = [word for word, flag in words_pos if word not in stopwords and flag in allowed_pos]\n",
    "\n",
    "    return ' '.join(filtered_words_pos)\n"
   ],
   "id": "943db44595fbffdc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 运行函数",
   "id": "6732e88f45baca2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T07:35:49.747628Z",
     "start_time": "2024-05-30T07:35:49.459348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = 'D:/基于机器学习的刑事案件分类技术/txt'\n",
    "stopwords = load_stopwords('D:/基于机器学习的刑事案件分类技术\\\\baidu_stopwords.txt')\n",
    "allowed_pos = {'n', 'v', 'a', 'd'}\n",
    "files = load_files(folder)\n",
    "all_texts = []\n",
    "labels = []\n",
    "for file in files:\n",
    "    text, label= clean_judgment_text(file)\n",
    "    labels.append(label)\n",
    "    all_texts.append(segment_and_filter(text, stopwords, allowed_pos))\n",
    "print(all_texts)\n",
    "print(labels)"
   ],
   "id": "422eac75854503c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['走私 毒品 犯', '因涉嫌 犯 珍贵 濒危 野生动物 罪 森林 逮捕 刑诉 字 起诉书 犯 珍贵 濒危 野生动物 本院 提起公诉 本院 依法 简易程序 实行 独任 开庭审理 到庭 参加 现已 终结 花鸟 市场 内 摆摊 黑 斑 头 均 属 国家 保护 动物 环颈雉 时许 公安人员 抓获 上述事实 开庭 过程 刑事案件 受理 抓获 现场 辨认 笔录 照片 扣押 物品 清单 动植物 物种 鉴定 证明 来源 野生动物 收条 户籍 证明 证实 本院认为 违反 国家 野生动物 保护 法规 国家 重点保护 珍贵 濒危 野生动物 已 珍贵 濒危 野生动物 归案 认罪态度 好 酌情 从轻 处罚 刑法 百 条 判决 犯 珍贵 濒危 野生动物 判处 拘役 判决 执行 计算 判决 执行 先行 羁押 羁押 折抵 起至 止 处罚金 人民币 罚金 判决 内 缴纳 不 缴纳 强制 缴纳 不服 判决 接到 判决书 内 本院 提出 书面 应 提交 上诉状 正本 副本', '原 上诉人 原审 男 日出 生于 小学文化 潜捕 船 所有人 船长 因涉嫌 犯 责任事故 逮捕 原审 责任事故 作出 原审 不服 提出 本院 依法 合议庭 审阅 案卷 材料 依法 讯问 原审 不 开庭审理 现已 终结 原判 认定 潜捕 船 所有人 船长 持有 驾驶员 职务 证书 驾驶 船舶 海域 返航 电建 渔港 进港 未 渔港 电建 大队 办理 签证 未 接受 不 履行 职责 未到 渔港 电建 大队 办理 签证 接受 情况 驾驶 船舶 搭载 黄 文 名 船员 均 办理 渔业 船 专业 基础训练 合格证书 不 出航 条件 情况 擅自 电建 渔港 出发 海域 潜捕 作业 时 分许 驾船 航行 东经 海域 船因 尾轴筒 受损 进水 连接 门 胶管 脱落 致使 海水 涌入 机舱 见状 文 报警 组织 全体人员 排水 自救 无效 潜捕 船 沉没 跳入 等待 获救 船员 溺水 死亡 船员 黄 失踪 公安 边防 总队 海警 支队 投案 家属 黄 达成 赔偿 协议 赔偿 被害人 约定 一次性 赔偿 失踪 已 支付 一次性 赔偿 失踪 已 支付 出狱 内 一次性 被害人 均 予以 谅解 原判 认定 上述事实 证人 证言 接受 刑事案件 户籍 证明 船 船员 持证 情况 渔业 船舶 所有权证 渔业 船舶 登记 证书 渔业 捕捞 渔业 船舶 证书 证明 渔船 自沉 事故 报告书 归案 调解 协议书 谅解 书 收条 书证 尸体 鉴定 意见书 鉴定结论 原判 作业 违反 发生 伤亡事故 致 死亡 失踪 已 责任事故 自首 情节 案发后 赔偿 被害人 损失 被害人 谅解 从轻 处罚 原判 犯罪事实 性质 情节 社会 危害 程度 刑法 判决 责任事故 判处 原审 提出 原判 错误 量刑 不当 驾驶 潜捕 船 出海 作业 时因 船 机械故障 导致 重大事故 出海 未 渔港 电建 大队 办理 签证 行政处罚 船舶 发生 机械故障 因果关系 自首 案发后 赔偿 被害人 经济损失 被害人 谅解 刑法 相关 司法解释 符合 宣告 缓刑 条件 请求 本院 从轻 减轻 处罚 缓刑 上诉人 检察机关 均 提交 新 事实 一审 采信 均 一审 庭审 认证 查证 属实 本院 予以 确认 本院 上诉人 家属 支付 失踪 人员 人民币 本院 被害人 失踪 人员 黄 询问 上诉人 侄儿 案发后 后事 亲属 已 陆续 支付 人民币 约 黄 均 请求 本院 宣告 缓刑 使 尽早 履行 赔偿 协议 本院认为 上诉人 事故 船舶 所有人 船长 案发 驾驶 船舶 进出港 时 未 部门 签证 接受 不 具备 出航 条件 情况 驾驶 事故 船舶 出海 作业 引发 重大事故 死亡 失踪 责任事故 提出 未 渔港 电建 大队 办理 签证 船舶 发生 机械故障 因果关系 意见 驾驶 船舶 出海 作业 没 相关 接受 违返 未能 导致 事故 发生 意见 事实 本院 不予 采信 原判 认定 上诉人 投案 如实 犯罪事实 自首 依法 从轻 减轻 处罚 案发后 赔偿 被害人 亲属 损失 谅解 本院 赔偿 被害人 亲属 损失 被害人 亲属 本院 请求 上诉人 判处 缓刑 上诉人 情节 悔罪 表现 宣告 缓刑 社区 使 及早 履行 被害人 家属 赔偿 协议 本院 宣告 缓刑 请求 宣告 缓刑 意见 本院 予以 采纳 刑法 条 刑事诉讼法 判决 责任事故 判处 上诉人 原审 责任事故 判处 缓刑 缓刑 期限 判决 计算 判决 审判长 红 判决 刑法 投案 如实 罪行 自首 自首 犯罪分子 从轻 减轻 处罚 较轻 免除 处罚 强制措施 嫌疑人 服刑 罪犯 如实 司法机关 还 未 罪行 自首 嫌疑人 不 自首 情节 如实 罪行 从轻 处罚 如实 罪行 特别 发生 减轻 处罚 判处 拘役 犯罪分子 符合 条件 宣告 缓刑 不满 怀孕 妇女 已 满 宣告 缓刑 情节 轻 悔罪 表现 再 宣告 缓刑 居住 社区 宣告 缓刑 情况 禁止 犯罪分子 缓刑 期限内 特定 特定 区域 场所 接触 特定 宣告 缓刑 犯罪分子 判处 附加刑 附加刑 仍须 执行 判处 拘役 犯罪分子 犯罪分子 情节 悔罪 表现 缓刑 再 危害 社会 宣告 缓刑 宣告 缓刑 犯罪分子 判处 附加刑 附加刑 仍须 执行 条 拘役 缓刑 期限 原判 少于 缓刑 期限 原判 少于 缓刑 期限 判决 计算 作业 违反 发生 伤亡事故 处 拘役 情节 特别 恶劣 处 强令 冒险 作业 发生 伤亡事故 处 拘役 情节 特别 恶劣 处 刑事诉讼法 条 第二审 不服 抗诉 案件 情形 原 判决 认定 事实 量刑 裁定 驳回上诉 抗诉 维持原判 原 判决 认定 事实 错误 错误 量刑 不当 原 判决 事实 不 证据不足 事实 裁定 发回 原审']\n",
      "[['强奸罪', '故意杀人罪'], [], ['重大责任事故罪', '罪情节及悔罪', '罪分子的犯罪情节和悔罪']]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 将文本转化为TF-IDF向量。",
   "id": "6de14787ebf8ed28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 使用TfidfVectorizer生成TF-IDF特征向量\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# 输出TF-IDF模型的特征名称和特征向量\n",
    "print(\"TF-IDF模型特征向量:\\n\", X_tfidf.toarray())"
   ],
   "id": "69c64818a07ca0fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 使用PCA算法进行降维\n",
    "\n",
    "经过TF-IDF算法处理后得到了一个多维的文本向量。\n",
    "\n",
    "因为文本是多维度的，使用PCA算法对文本向量进行降维，保留最重要特征的同时简化向量，提高训练模型的性能"
   ],
   "id": "303131591df8b046"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 使用PCA对TF-IDF特征向量进行降维\n",
    "from sklearn.decomposition import PCA\n",
    "n_components = 2 # 需要保留的主成分数量，可以根据实际情况调整\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "# 输出降维后的特征向量\n",
    "print(\"降维后的特征向量:\\n\", X_pca)\n",
    "\n",
    "# 输出保留的方差比例\n",
    "print(\"各主成分的方差解释比例:\", pca.explained_variance_ratio_)\n",
    "print(\"总方差解释比例:\", sum(pca.explained_variance_ratio_))"
   ],
   "id": "e46cd3be45fdfe76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*进度:可以提取出罪名以及处罚作为标签，再划分测试集训练集。使用分类算法*",
   "id": "f16fbc9ff80aacd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
